import pandas as pd
import json
import argparse
import sys
import os
import glob
from tqdm import tqdm

def format_dataset_to_prompt_response(row):
    """
    è½¬æ¢ OpenCodeInstruct-like çš„ DataFrameè¡Œ (row) ä¸º 'prompt/response' æ ¼å¼ã€‚

    å‡è®¾: 
    - æ–°æ•°æ®é›†çš„åˆ—åæ˜¯ 'input' (ç¼–ç é—®é¢˜) å’Œ 'output' (å¤§æ¨¡å‹çš„å›ç­”)ã€‚
    """
    
    # -----------------------------------------------------------------
    # ğŸ‘‡ é‡è¦ï¼šæ ¹æ®ä½ çš„æ–°æ•°æ®é›†åˆ—åè¿›è¡Œæ˜ å°„
    # -----------------------------------------------------------------
    # ä½ çš„æ–°æ ¼å¼ä¸­ï¼Œ'input' æ˜¯ç¼–ç é—®é¢˜ï¼Œ'output' æ˜¯å›ç­”ã€‚
    
    instruction = row.get('input')
    output = row.get('output')
    
    # å¦‚æœåˆ—åä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©ºï¼Œåˆ™è·³è¿‡
    if not instruction or not output:
        return None

    # -----------------------------------------------------------------
    
    # æ ¹æ® code_alpaca æ ¼å¼æ„å»º prompt
    # æ–°æ ¼å¼çš„ 'input' å­—æ®µæœ¬èº«å°±æ˜¯å®Œæ•´çš„æŒ‡ä»¤ï¼Œæ‰€ä»¥ 'input' è®¾ä¸ºç©º
    input_str = "< noinput >"

    prompt_template = (
        "Instruction:\n{instruction}\n\nInput:\n{input_str}\n\nAnswer:"
    )
    prompt = prompt_template.format(instruction=instruction, input_str=input_str)

    return {"prompt": prompt, "response": output}

def main():
    parser = argparse.ArgumentParser(description="å°†ä¸€ä¸ªç›®å½•ä¸­çš„æ‰€æœ‰ .parquet è½¬æ¢ä¸º 'prompt/response' (.jsonl) æ ¼å¼")
    parser.add_argument(
        '--source_dir', 
        type=str, 
        required=True, 
        help="åŒ…å« .parquet æ–‡ä»¶çš„æºç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        '--output_file', 
        type=str, 
        required=True, 
        help="åˆå¹¶åçš„è¾“å‡º .jsonl æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        '--max_entries',
        type=int,
        default=None,
        help="ï¼ˆå¯é€‰ï¼‰å¤„ç† N æ¡æ•°æ®ååœæ­¢ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•"
    )

    args = parser.parse_args()

    # -----------------------------------------------------------------
    # ğŸ‘‡ æ›´æ”¹ï¼šæœç´¢ç›®å½•è€Œä¸æ˜¯è¯»å–å•ä¸ªæ–‡ä»¶
    # -----------------------------------------------------------------
    print(f"ğŸš€ å¼€å§‹æœç´¢ç›®å½•: {args.source_dir}")
    
    # ä½¿ç”¨ glob é€’å½’æœç´¢æ‰€æœ‰ .parquet æ–‡ä»¶
    search_path = os.path.join(args.source_dir, "**", "*.parquet")
    source_files = glob.glob(search_path, recursive=True)

    if not source_files:
        print(f"é”™è¯¯: åœ¨ '{args.source_dir}' ä¸­æœªæ‰¾åˆ° .parquet æ–‡ä»¶ã€‚", file=sys.stderr)
        sys.exit(1)

    print(f"ğŸ” æ‰¾åˆ°äº† {len(source_files)} ä¸ª .parquet æ–‡ä»¶:")
    for f in source_files:
        print(f"  - {f}")
    # -----------------------------------------------------------------

    print(f"\nğŸ¯ å¼€å§‹è½¬æ¢å¹¶å†™å…¥åˆ°: {args.output_file}")

    processed_count = 0
    skipped_count = 0
    stop_processing = False

    try:
        # ä¸€æ¬¡æ€§æ‰“å¼€è¾“å‡ºæ–‡ä»¶
        with open(args.output_file, 'w', encoding='utf-8') as f_out:
            
            # éå†æ‰¾åˆ°çš„æ¯ä¸ªæ–‡ä»¶
            for source_file in source_files:
                if stop_processing:
                    break
                
                print(f"\nProcessing file: {source_file}")
                
                try:
                    df = pd.read_parquet(source_file)
                    print(f"  æºæ–‡ä»¶è¡Œæ•°: {len(df)}")
                    
                    # æ‰“å°åˆ—åæ£€æŸ¥ (ä»…ç¬¬ä¸€ä¸ªæ–‡ä»¶)
                    if processed_count == 0 and len(df) > 0:
                        print("\n  --- åˆ—åæ£€æŸ¥ (æ–‡ä»¶é¦–è¡Œ) ---")
                        preview_cols = [col for col in ['input', 'output'] if col in df.columns]
                        if not preview_cols:
                            print(f"  è­¦å‘Š: åœ¨æºæ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'input' æˆ– 'output' åˆ—ã€‚")
                            print(f"  æ‰¾åˆ°çš„åˆ—: {df.columns.tolist()}")
                        else:
                            print(df[preview_cols].head(1))
                        print("  ----------------------------\n")

                except Exception as e:
                    print(f"  é”™è¯¯: æ— æ³•è¯»å– Parquet æ–‡ä»¶ {source_file}. {e}", file=sys.stderr)
                    print("  è¯·ç¡®ä¿ä½ å·²è¿è¡Œ: pip install pandas pyarrow", file=sys.stderr)
                    skipped_count += 1 # æ ‡è®°æ•´ä¸ªæ–‡ä»¶ä¸ºâ€œè·³è¿‡â€
                    continue # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶

                # ä½¿ç”¨ tqdm æ˜¾ç¤ºå½“å‰æ–‡ä»¶çš„å¤„ç†è¿›åº¦
                for _, row in tqdm(df.iterrows(), total=len(df), desc=f"  -> {os.path.basename(source_file)}"):
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°äº† max_entries é™åˆ¶
                    if args.max_entries and processed_count >= args.max_entries:
                        print(f"\nâš ï¸ å·²è¾¾åˆ° {args.max_entries} æ¡æ•°æ®çš„æœ€å¤§é™åˆ¶ï¼Œåœæ­¢å¤„ç†ã€‚")
                        stop_processing = True
                        break

                    formatted_entry = format_dataset_to_prompt_response(row)
                    
                    if formatted_entry:
                        json.dump(formatted_entry, f_out, ensure_ascii=False)
                        f_out.write('\n')
                        processed_count += 1
                    else:
                        skipped_count += 1

    except Exception as e:
        print(f"\nå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        
    print("\n" + "="*50)
    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"å·²å¤„ç†æ¡ç›®: {processed_count}")
    print(f"å·²è·³è¿‡æ¡ç›®: {skipped_count} (å¯èƒ½åŒ…å«æ— æ•ˆè¡Œæˆ–æ— æ³•è¯»å–çš„æ•´ä¸ªæ–‡ä»¶)")
    print(f"æ€»è¾“å‡ºæ–‡ä»¶: {args.output_file}")

if __name__ == "__main__":
    main()